knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(Stat2Data)
library(glue)
library(lawstat)
#see if intercation is necceserty
data(Ricci)
full_model <- lm(Combine ~ Position*Race,data = Ricci)
no_inter_model <- lm(Combine ~ Position + Race,data = Ricci)
anov_test <- anova(no_inter_model,full_model)
pv <- anov_test[["Pr(>F)"]][2]
glue("interaction relevence p value is: {pv} therefore we will not reject the null, meaning the interaction is not needed")
#assumptions
glue("we assume equal variance")
levene_test <-levene.test(Ricci$Combine,Ricci$Race:Ricci$Position,location = "mean")
glue("pvalue for levene test is {round(levene_test$p.value,4)} therefore we will not reject the null and conclude equal varicane")
glue("we assume normality of the residuals")
ggplot(Ricci,aes(sample = Combine - predict(no_inter_model,Ricci[c("Position","Race")]))) +
stat_qq()+
stat_qq_line()+
ggtitle("error normality check")
glue("looks ok")
glue("we also assume independece but we cant check it")
#balance check
Ricci %>%
group_by(Position,Race) %>%
summarize(n())
glue("we can see that the groups are unbalanced")
glue("it mneas that SST =/= SSA +SSB + SSAB + SSE")
#show means
Ricci %>%
group_by(Position,Race) %>%
summarize(mean(Combine))
Ricci %>%
group_by(Position) %>%
summarize(mean(Combine))
Ricci %>%
group_by(Race) %>%
summarize(mean(Combine))
#anova for Position
Pos_model <- lm(Combine ~ Race ,data = Ricci)
anov_test_pos <- anova(Pos_model,no_inter_model)
pv_pos <- anov_test_pos[["Pr(>F)"]][2]
glue("interaction relevence p value is: {pv_pos} therefore we will not reject the null, meaning that position has no effect on test results")
#anova for Race
Race_model <- lm(Combine ~ Position ,data = Ricci)
anov_test_R <- anova(Race_model,no_inter_model)
pv_R <- anov_test_R[["Pr(>F)"]][2]
glue("interaction relevence p value is: {pv_R} therefore we will reject the null, meaning that race has an effect on test results")
library(multcomp)
contr <- rbind(
"Race H - Race B" = c(-1,1,0),
"Race W - Race B" = c(-1,0,1),
"Race W - Race H" = c(0,-1,1)
)
aov_model <-no_inter_model
pair_wise <- glht(aov_model, linfct = mcp(Race = contr))
glue("bonferroni method results:")
summary(pair_wise, test = adjusted(type = "bonf"))
glue("Tukey method results:")
summary(glht(aov_model, mcp(Race = "Tukey")), test = univariate())
glue("we can conculde from both methods that there is a difference between: whites and blacks, whites and hispanics for FWER = 0.05 ")
library(multcomp)
contr <- rbind(
"Race H - Race B" = c(-1,1,0),
"Race W - Race B" = c(-1,0,1),
"Race W - Race H" = c(0,-1,1)
)
aov_model <-no_inter_model
pair_wise <- glht(aov_model, linfct = mcp(Race = contr))
glue("bonferroni method results:")
summary(pair_wise, test = adjusted(type = "bonf"))
glue("Tukey method results:")
summary(glht(aov_model, mcp(Race = "Tukey")), test = univariate())
glue("we can conculde from both methods that there is a difference between: whites and blacks, whites and hispanics for FWER = 0.05 ")
aov_model <- aov(Combined~Race,data = Ricci)
aov_model <- aov(Combine~Race,data = Ricci)
aov_model
summary(aov_model)
#assumptions
glue("we assume equal variance")
levene_test <-levene.test(Ricci$Combine,Ricci$Race,location = "mean")
levene_test
levene_test <-levene.test(Ricci$Combine,Ricci$Race,location = "mean")
glue("pvalue for levene test is {round(levene_test$p.value,4)} therefore we will not reject the null and conclude equal varicane")
glue("we assume normality of the residuals")
ggplot(Ricci,aes(sample = Combine - predict(lm(Combine~Race,data = Ricci),Ricci[c("Position","Race")]))) +
stat_qq()+
stat_qq_line()+
ggtitle("error normality check")
glue("looks ok")
glue("we also assume independece but we cant check it")
knitr::opts_chunk$set(echo = TRUE,message = FALSE)
aov_model <- aov(Combine~Race,data = Ricci)
summary(aov_model)
glue("we can reject the null and conclude at a confidance level of 95% that RAce effects the Combined score")
#assumptions
glue("we assume equal variance")
levene_test <-levene.test(Ricci$Combine,Ricci$Race,location = "mean")
glue("pvalue for levene test is {round(levene_test$p.value,4)} therefore we will not reject the null and conclude equal varicane")
glue("we assume normality of the residuals")
ggplot(Ricci,aes(sample = Combine - predict(lm(Combine~Race,data = Ricci),Ricci[c("Position","Race")]))) +
stat_qq()+
stat_qq_line()+
ggtitle("error normality check")
glue("looks ok")
glue("we also assume independece but we cant check it")
contr <- rbind(
"Race H - Race B" = c(-1,1,0),
"Race W - Race B" = c(-1,0,1),
"Race W - Race H" = c(0,-1,1)
)
pair_wise <- glht(aov_model, linfct = mcp(Race = contr))
glue("bonferroni method results:")
summary(pair_wise, test = adjusted(type = "bonf"))
glue("Tukey method results:")
summary(glht(aov_model, mcp(Race = "Tukey")), test = univariate())
glue("we can conculde from both methods that there is a difference between: whites and blacks, whites and hispanics for FWER = 0.05 ")
knitr::opts_chunk$set(echo = TRUE)
feed_back_cont <- feed_back %>%
select(id,preformance,feedback) %>%
filter(feedback == "no feedback")
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,preformance,feedback) %>%
filter(feedback == "no feedback")
#imports
library(tidyverse)
library(glue)
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,preformance,feedback) %>%
filter(feedback == "no feedback")
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
feed_back_cont
library(lme4)
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
rand_a <- lmer(performance ~ (1|id) , data = feed_back_cont)
summary(rand_a)
rand_a
View(rand_a)
summary(rand_a)
anova(rand_a)
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
rand_a <- lmer(performance ~ (1|id) , data = feed_back_cont)
anova(rand_a)
rand(rand_a)
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
rand_a <- lmer(performance ~ (1|id) , data = feed_back_cont)
summary(rand_a)
sigma_a <- 68.69
sigma_e <- 67.29
MSE <-  sigma_e
MSA <- n*sigma_a+MSE
n <-  12
MSA <- n*sigma_a+MSE
MSE
MSA
f_stat <- MSA/MSE
summary(rand_a)
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
rand_a <- lmer(performance ~ (1|id) , data = feed_back_cont)
summary(rand_a)
n <-  12
I <- 22
N <- n*I
sigma_a <- 68.69
sigma_e <- 67.29
MSE <-  sigma_e
MSA <- n*sigma_a+MSE
f_stat <- MSA/MSE
pf(f_stat,I-1,N-I)
f_stat
pf(f_stat,I-1,N-I,lower.tail = TRUE)
pf(f_stat,I-1,N-I,lower.tail = FALSE)
pf(f_stat,I-1,N-I,lower.tail = FALSE) <=0.05
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
rand_a <- lmer(performance ~ (1|id) , data = feed_back_cont)
summary(rand_a)
n <-  12
I <- 22
N <- n*I
sigma_a <- 68.69
sigma_e <- 67.29
MSE <-  sigma_e
MSA <- n*sigma_a+MSE
f_stat <- MSA/MSE
glue("pvalue is: {pf(f_stat,I-1,N-I,lower.tail = FALSE)} thus we will reject the null with a confidance level of 95%")
feed_back <- read.csv("feedback_df_bi.csv")
feed_back_cont <- feed_back %>%
select(id,performance,feedback) %>%
filter(feedback == "no feedback")
rand_a <- lmer(performance ~ (1|id) , data = feed_back_cont)
summary(rand_a)
n <-  12
I <- 22
N <- n*I
sigma_a <- 68.69
sigma_e <- 67.29
mu <- 89.503
MSE <-  sigma_e
MSA <- n*sigma_a+MSE
f_stat <- MSA/MSE
glue("pvalue is: {pf(f_stat,I-1,N-I,lower.tail = FALSE)} thus we will reject the null with a confidance level of 95%")
glue("the estimators are:
mu = {mu}
sigma alpha = {sigma_a}
sigma epsilon = {sigma_e}")
ci_mu <- mu +c(-1,1)*qt(0.975,I-1)*sqrt(MSA)
ci_mu <- mu +c(-1,1)*qt(0.975,I-1)*sqrt(MSA)
glue("ci for mu is:({ci_mu[1]},{ci_mu[2]})")
alpha <- 0.05
ci_sigma_e <- MSE*(N-I)/(qchisq(1-alpha/2,N-I),qchisq(alpha/2,N-I))
alpha <- 0.05
ci_sigma_e <- MSE*(N-I)/c(qchisq(1-alpha/2,N-I),qchisq(alpha/2,N-I))
glue("ci at a confidance level of 95% for sigma epsilon is:({ci_sigma_e[1]},{ci_sigma_e[2]})")
ci_sigma_a = s_p(n,I,MSA,MSE,alpha)
s_p <- function(n,I,MSA,MSE,alpha){
N <- n*I
c_s <- c(1/N,-1/N)
Ms <- c(MSA,MSE)
df <- c(I-1,N-I)
sigma_hat <- c_s %*% Ms
df_sigma = (sigma_hat)^2/ saum(cs^2*Ms*2/df)
u_q <- qchisq(1-alpha/2,df_sigma)
l_q <- qchisq(alpha/2,df_sigma)
ci <- c(df_sigma*sigma_hat/u_q,df_sigma*sigma_hat/l_q)
return(ci)
}
ci_sigma_a = s_p(n,I,MSA,MSE,alpha)
s_p <- function(n,I,MSA,MSE,alpha){
N <- n*I
c_s <- c(1/N,-1/N)
Ms <- c(MSA,MSE)
df <- c(I-1,N-I)
sigma_hat <- c_s %*% Ms
df_sigma = (sigma_hat)^2/ sum(cs^2*Ms*2/df)
u_q <- qchisq(1-alpha/2,df_sigma)
l_q <- qchisq(alpha/2,df_sigma)
ci <- c(df_sigma*sigma_hat/u_q,df_sigma*sigma_hat/l_q)
return(ci)
}
ci_sigma_a = s_p(n,I,MSA,MSE,alpha)
s_p <- function(n,I,MSA,MSE,alpha){
N <- n*I
c_s <- c(1/N,-1/N)
Ms <- c(MSA,MSE)
df <- c(I-1,N-I)
sigma_hat <- c_s %*% Ms
df_sigma = (sigma_hat)^2/ sum(c_s^2*Ms*2/df)
u_q <- qchisq(1-alpha/2,df_sigma)
l_q <- qchisq(alpha/2,df_sigma)
ci <- c(df_sigma*sigma_hat/u_q,df_sigma*sigma_hat/l_q)
return(ci)
}
ci_sigma_a = s_p(n,I,MSA,MSE,alpha)
glue("ci at a confidance level of 95% for sigma alpha is:({ci_sigma_a[1]},{ci_sigma_a[2]})")
N <- n*I
c_s <- c(1/N,-1/N)
c_s
Ms <- c(MSA,MSE)
Ms
df
df <- c(I-1,N-I)
sigma_hat <- c_s %*% Ms
c_s %*% Ms
N <- n*I
c_s <- c(1/n,-1/n)
Ms <- c(MSA,MSE)
df <- c(I-1,N-I)
sigma_hat <- c_s %*% Ms
df_sigma = (sigma_hat)^2/ sum(c_s^2*Ms*2/df)
u_q <- qchisq(1-alpha/2,df_sigma)
l_q <- qchisq(alpha/2,df_sigma)
ci <- c(df_sigma*sigma_hat/u_q,df_sigma*sigma_hat/l_q)
ci
sigma_hat
df_sigma
df_sigma = (sigma_hat)^2/ sum(c_s^2*Ms^2/df)
df_sigma
u_q <- qchisq(1-alpha/2,df_sigma)
l_q <- qchisq(alpha/2,df_sigma)
ci
ci <- c(df_sigma*sigma_hat/u_q,df_sigma*sigma_hat/l_q)
ci
s_p <- function(n,I,MSA,MSE,alpha){
N <- n*I
c_s <- c(1/n,-1/n)
Ms <- c(MSA,MSE)
df <- c(I-1,N-I)
sigma_hat <- c_s %*% Ms
df_sigma = (sigma_hat)^2/ sum(c_s^2*Ms^2/df)
u_q <- qchisq(1-alpha/2,df_sigma)
l_q <- qchisq(alpha/2,df_sigma)
ci <- c(df_sigma*sigma_hat/u_q,df_sigma*sigma_hat/l_q)
return(ci)
}
ci_sigma_a = s_p(n,I,MSA,MSE,alpha)
glue("ci at a confidance level of 95% for sigma alpha is:({ci_sigma_a[1]},{ci_sigma_a[2]})")
ci_ICC <- ((MSA/MSE)* c(qf(1-alpha/2,I-1,N-I),qf(alpha/2,I-1,N-I)) -1)/n
glue("ci at a confidance level of 95% for ICC is:({ci_ICC[1]},{ci_ICC[2]})")
L_U <- ((MSA/MSE)* c(qf(1-alpha/2,I-1,N-I),qf(alpha/2,I-1,N-I)) -1)/n
L <- L_U[1]
U <- L_U[2]
ci_ICC <- c(L/(L+1),U/(U+1))
glue("ci at a confidance level of 95% for ICC is:({ci_ICC[1]},{ci_ICC[2]})")
L_U <- ((MSA/MSE)/c(qf(1-alpha/2,I-1,N-I),qf(alpha/2,I-1,N-I)) -1)/n
L <- L_U[1]
U <- L_U[2]
ci_ICC <- c(L/(L+1),U/(U+1))
glue("ci at a confidance level of 95% for ICC is:({ci_ICC[1]},{ci_ICC[2]})")
ci_mu <- round(mu +c(-1,1)*qt(0.975,I-1)*sqrt(MSA),3)
glue("ci at a confidance level of 95% for mu is:({ci_mu[1]},{ci_mu[2]})")
alpha <- 0.05
ci_sigma_e <- round(MSE*(N-I)/c(qchisq(1-alpha/2,N-I),qchisq(alpha/2,N-I)),3)
glue("ci at a confidance level of 95% for sigma epsilon is:({ci_sigma_e[1]},{ci_sigma_e[2]})")
ci_sigma_a = round(s_p(n,I,MSA,MSE,alpha),3)
glue("ci at a confidance level of 95% for sigma alpha is:({ci_sigma_a[1]},{ci_sigma_a[2]})")
L_U <- ((MSA/MSE)/c(qf(1-alpha/2,I-1,N-I),qf(alpha/2,I-1,N-I)) -1)/n
L <- L_U[1]
U <- L_U[2]
ci_ICC <- round(c(L/(L+1),U/(U+1)),3)
glue("ci at a confidance level of 95% for ICC is:({ci_ICC[1]},{ci_ICC[2]})")
confint(rand_a)
ci_mu <- round(mu +c(-1,1)*qt(0.975,I-1)*sqrt(MSA/N),3)
glue("ci at a confidance level of 95% for mu is:({ci_mu[1]},{ci_mu[2]})")
