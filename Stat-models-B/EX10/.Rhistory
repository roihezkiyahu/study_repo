step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_size <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(size) %>%
step_texthash(size, signed = FALSE, num_terms = 2^4) %>%
step_pca(starts_with("location_hash"),threshold = 0.8,prefix = "PC_loc") %>%
step_pca(starts_with("title"),threshold = 0.8,prefix = "PC_title") %>%
step_pca(starts_with("size"),threshold = 0.95,prefix = "PC_size") %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_num_comp <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_pca(starts_with("location_hash"),num_comp = 30,prefix = "PC_loc") %>%
step_pca(starts_with("title"),num_comp = 30,prefix = "PC_title") %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_no_step_text <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_pca(starts_with("location_hash"),threshold = 0.8,prefix = "PC_loc") %>%
step_pca(starts_with("title"),threshold = 0.8,prefix = "PC_title")
my_rec_with_text_brand_other5 <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.05)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(c(more_then_70_precent_missing,-all_numeric(),n_sold,n_watchers,-has_na_ship),fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_pca(starts_with("location_hash"),threshold = 0.8,prefix = "PC_loc") %>%
step_pca(starts_with("title"),threshold = 0.8,prefix = "PC_title") %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
#embedings:
my_rec_with_text_embed <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_pls(starts_with("location_hash"),outcome = "log_price",num_comp = 30,prefix = "PC_loc") %>%
step_pls(starts_with("title"),outcome = "log_price",num_comp = 30,prefix = "PC_title") %>%
step_nzv(all_numeric()) %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_embed_brand <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(brand) %>%
step_texthash(brand, signed = FALSE, num_terms = 2^4) %>%
step_pls(starts_with("location_hash"),outcome = "log_price",num_comp = 20,prefix = "PC_loc") %>%
step_pls(starts_with("title"),outcome = "log_price",num_comp = 20,prefix = "PC_title") %>%
step_pls(starts_with("brand"),outcome = "log_price",num_comp = 20,prefix = "PC_brande") %>%
step_nzv(all_numeric()) %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_embed_color <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(color) %>%
step_texthash(color, signed = FALSE, num_terms = 2^4) %>%
step_pls(starts_with("location_hash"),outcome = "log_price",num_comp = 20,prefix = "PC_loc") %>%
step_pls(starts_with("title"),outcome = "log_price",num_comp = 20,prefix = "PC_title") %>%
step_pls(starts_with("color"),outcome = "log_price",num_comp = 10,prefix = "PC_color") %>%
step_nzv(all_numeric()) %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_embed_style <- recipe(log_price ~ ., data = shoes_train_text_tr) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),more_then_70_precent_missing,-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(style) %>%
step_texthash(style, signed = FALSE, num_terms = 2^4) %>%
step_pls(starts_with("location_hash"),outcome = "log_price",num_comp = 20,prefix = "PC_loc") %>%
step_pls(starts_with("title"),outcome = "log_price",num_comp = 20,prefix = "PC_title") %>%
step_pls(starts_with("style"),outcome = "log_price",num_comp = 20,prefix = "PC_style") %>%
step_nzv(all_numeric()) %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),textfeature_t_title_n_caps,ends_with("urls"),textfeature_t_title_politeness,ends_with("person"),
ends_with("personp"),textfeature_t_title_to_be,textfeature_t_title_prepositions)
my_rec_with_text_embed
# cv for feature pca and hashingtext features
cv_V = 5
cv_splits <- vfold_cv(shoes_train_text, v = cv_v)
cv_results_text <- tibble("my_rec" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec),
"1" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_embed),
"2" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_color_w_step),
"6" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_lining_material),
"7" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_material),
"8" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_color),
"9" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_brand_other5),
"10" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text),
"11" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_no_step_text),
"12" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_style),
"13" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_rm_70),
"14" = map_dbl(cv_splits$splits,fit_lr_text,rec = my_rec_with_text_rm)
)
cv_results_longer <- cv_results_text %>%
pivot_longer(cols = colnames(cv_results_text),names_to = "recipe",values_to = "rmse") %>% mutate(fold = ceiling(1:(length(colnames(cv_results_text))*cv_v)/length(colnames(cv_results_text))))
cv_results_longer %>% group_by(recipe) %>% summarize(m = median(rmse)) %>% arrange(m)
cv_results_longer %>%
ggplot(aes(recipe, rmse,group=fold,color = fold)) +
geom_line() +
geom_point() +
guides(color = "none") +
theme_light()
my_rec_with_text_last <- recipe(log_price ~ ., data = shoes_train_interaction_tr_imp) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_pca(starts_with("location_hash"),threshold = 0.8,prefix = "PC_loc") %>%
step_pca(starts_with("title"),threshold = 0.8,prefix = "PC_title") %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),ends_with("n_caps"),ends_with("urls"),ends_with("politeness"),ends_with("person"),
ends_with("personp"),ends_with("_to_be"),ends_with("prepositions"),more_then_70_precent_missing)
train_df_imp <- my_rec_with_text_last%>%
prep(shoes_train_interaction_tr_imp) %>%
bake(new_data = shoes_train_interaction_tr_imp)
train_df_imp <- my_rec_with_text_last%>%
prep(shoes_train_interaction_tr_imp) %>%
bake(new_data = shoes_train_interaction_tr_imp)
test_df_imp <- my_rec_with_text_last%>%
prep(shoes_train_interaction_tr_imp) %>%
bake(new_data = shoes_train_interaction_val_imp)
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits_tune,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
en_grid <- grid_regular(penalty(range(-6, 0)),
mixture(range(0, 1)),
levels = c(7, 11))
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits_tune,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
mod_en_tune <- logistic_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet")
en_grid <- grid_regular(penalty(range(-6, 0)),
mixture(range(0, 1)),
levels = c(7, 11))
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits_tune,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
mod_en_tune <- linear_reg(penalty = tune(),
mixture = tune(),
) %>%
set_engine("glmnet")
en_grid <- grid_regular(penalty(range(-6, 0)),
mixture(range(0, 1)),
levels = c(7, 11))
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
my_rec_with_text_last <- recipe(log_price ~ ., data = shoes_train_interaction_tr_imp) %>%
step_mutate(t_title = title) %>%
step_other(brand,threshold = 0.001)%>%
step_other(fastening,lining_material,shoe_width,size,color,style,location_state,heel_height,material,threshold = 0.05)%>%
step_mutate_at(more_then_70_precent_missing,fn = is.na)%>%
step_mutate_at(c(all_numeric(),-log_price,-id),fn=factor)%>%
step_tokenize(title) %>%
step_texthash(title, signed = FALSE, num_terms = 2^8) %>%
step_tokenize(location) %>%
step_texthash(location, signed = FALSE, num_terms = 2^8) %>%
step_pca(starts_with("location_hash"),threshold = 0.8,prefix = "PC_loc") %>%
step_pca(starts_with("title"),threshold = 0.8,prefix = "PC_title") %>%
step_textfeature(t_title,extract_functions = c(textfeatures::count_functions,"sent_bing" = textfeatures:::sentiment_bing)) %>%
step_rm(ends_with("hashtags"),ends_with("mentions"),ends_with("n_caps"),ends_with("urls"),ends_with("politeness"),ends_with("person"),
ends_with("personp"),ends_with("_to_be"),ends_with("prepositions"),more_then_70_precent_missing)
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
cv_splits <- vfold_cv(shoes_train_interaction_tr, v = cv_v)
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = cv_splits,
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
tune_res <- tune_grid(object = mod_en_tune,
preprocessor = my_rec_with_text_last,
resamples = vfold_cv(mutate_missing2(shoes_train_interaction_tr), v = cv_v),
grid = en_grid,
metrics = metric_set(rmse),
control = control_grid(verbose = TRUE))
mod_lr <- linear_reg(penalty = 0.01) %>%
set_engine("glmnet")
mod_lr <- linear_reg(penalty = 0.01) %>%
set_engine("glmnet")
lr_res <- mod_lr %>% fit(log_price ~ . -id, data = train_df_imp) %>% pluck("fit")  %>% tidy()
lr_res %>%
count(lambda) %>%
ggplot(aes(lambda, n)) +
geom_line(lwd = 2, color = "red", alpha = 0.5) +
labs(y = "N features selected by glmnet") +
theme_light()
lr_res %>%
filter(step == 6) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
lr_res %>%
count(lambda) %>%
ggplot(aes(lambda, n)) +
geom_line(lwd = 2, color = "red", alpha = 0.5) +
labs(y = "N features selected by glmnet") +
theme_light()
lr_res %>%
filter(step == 20) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
lr_res %>%
filter(step == 50) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
lr_res %>%
filter(step == 20) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
lr_res %>%
filter(step == 30) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
mod_lr <- linear_reg(penalty = 0.01) %>%
set_engine("glmnet")
lr_res <- mod_lr %>% fit(log_price ~ . -id, data = train_df_imp %>% select(-starts_with("PC"))) %>% pluck("fit")  %>% tidy()
lr_res %>%
count(lambda) %>%
ggplot(aes(lambda, n)) +
geom_line(lwd = 2, color = "red", alpha = 0.5) +
labs(y = "N features selected by glmnet") +
theme_light()
lr_res %>%
filter(step == 30) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
lr_res %>%
filter(step == 25) %>%
select(term, estimate) %>%
arrange(-abs(estimate))
control <- trainControl(method = "cv", number = 5)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
customRF <- list(type = "Regression", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
set.seed(seed)
set.seed(42)
custom <- train(log_price ~ . -id, data = train_df_imp, method=customRF, metric=rmse, tuneGrid=tunegrid, trControl=control)
custom <- train(log_price ~ . -id, data = train_df_imp, method=customRF, metric="rmse", tuneGrid=tunegrid, trControl=control)
customRF <- list(type = "Regression", library = "ranger", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
set.seed(42)
custom <- train(log_price ~ . -id, data = train_df_imp, method=customRF, metric="rmse", tuneGrid=tunegrid, trControl=control)
control <- trainControl(method = "cv", number = 5)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
customRF <- list(type = "Regression", library = "ranger", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
set.seed(42)
custom <- train(log_price ~ . -id, data = train_df_imp, method=customRF, metric="rmse", tuneGrid=tunegrid, trControl=control)
library(randomForest)
customRF <- list(type = "Regression", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
set.seed(42)
custom <- train(log_price ~ . -id, data = train_df_imp, method=customRF, metric="rmse", tuneGrid=tunegrid, trControl=control)
library(tidyverse)
setwd("C:/Users/Nir/Downloads")
install.packages("rlang_0.4.10.tar.gz", repos = NULL)
install.packages("rlang_0.4.10.tar.gz.zip", repos = NULL)
install.packages("R-4.2.0.tar.gz.zip", repos = NULL)
install.packages("R-4.2.0.tar.gz", repos = NULL)
install.packages("rlang", dependencies = TRUE)
library(tidyverse)
install.packages("rlang_0.4.10.tar.gz", repos = NULL, type="source")
remove.packages("rlang")
install.packages("dplyr")
packageVersion("dplyr")
remove.packages("dplyr")
install.packages("dplyr_1.0.9.tar.gz", repos = NULL, type="source")
setwd("C:/Users/Nir/Downloads")
install.packages("dplyr_1.0.9.tar.gz", repos = NULL, type="source")
library(dplyr)
setwd("C:/Users/Nir/Downloads")
install.packages("dplyr_1.0.9.tar.gz", repos = NULL, type="source")
knitr::opts_chunk$set(echo = TRUE)
library(glue)
library(tidyverse)
library(tidymodels)
library(caret)
library(MASS)
library(ResourceSelection)
bank <- read_csv("bank.csv") %>% dplyr::select(-1,-2) %>% mutate(y = ifelse(y=="yes",1,0))
full_model <- glm(y~.,data = bank,family = "binomial")
back <- MASS::stepAIC(full_model,method = "backward")
summary(back)
forward <- MASS::stepAIC(full_model,method = "forward")
summary(forward)
both <- MASS::stepAIC(full_model,method = "both")
summary(both)
mod_1 <-  glm(y~age+university+age*university,data = bank,family = "binomial")
mod_2 <-  glm(y~age+housing+age*housing,data = bank,family = "binomial")
mod_3 <-  glm(y~housing+university+housing*university,data = bank,family = "binomial")
CalcValidDev <- function(valid_preds, valid_y)
{
-2*(sum(valid_y*log(valid_preds) + (1-valid_y)*log(1-valid_preds)))
}
dev_1 <- c()
dev_2 <- c()
dev_3 <- c()
for (i in 1:nrow(bank)){
#data
bank_dat <- bank[-i,]
left_dat <- bank[i,]
#models
mod_1 <-  glm(y~age+university+age*university,data = bank_dat,family = "binomial")
mod_2 <-  glm(y~age+housing+age*housing,data = bank_dat,family = "binomial")
mod_3 <-  glm(y~housing+university+housing*university,data = bank_dat,family = "binomial")
#predictions
pred_1 <- as.numeric(predict(mod_1,left_dat,type = "response"))
pred_2 <- as.numeric(predict(mod_2,left_dat,type = "response"))
pred_3 <- as.numeric(predict(mod_3,left_dat,type = "response"))
#deviances
dev_1[i] <- CalcValidDev(pred_1,left_dat$y)
dev_2[i] <- CalcValidDev(pred_2,left_dat$y)
dev_3[i] <- CalcValidDev(pred_3,left_dat$y)
}
mod_1 <-  glm(y~age+university+age*university,data = bank,family = "binomial")
mod_2 <-  glm(y~age+housing+age*housing,data = bank,family = "binomial")
mod_3 <-  glm(y~housing+university+housing*university,data = bank,family = "binomial")
CalcValidDev <- function(valid_preds, valid_y)
{
-2*(sum(valid_y*log(valid_preds) + (1-valid_y)*log(1-valid_preds)))
}
dev_1 <- c()
dev_2 <- c()
dev_3 <- c()
for (i in 1:nrow(bank)){
print(i)
#data
bank_dat <- bank[-i,]
left_dat <- bank[i,]
#models
mod_1 <-  glm(y~age+university+age*university,data = bank_dat,family = "binomial")
mod_2 <-  glm(y~age+housing+age*housing,data = bank_dat,family = "binomial")
mod_3 <-  glm(y~housing+university+housing*university,data = bank_dat,family = "binomial")
#predictions
pred_1 <- as.numeric(predict(mod_1,left_dat,type = "response"))
pred_2 <- as.numeric(predict(mod_2,left_dat,type = "response"))
pred_3 <- as.numeric(predict(mod_3,left_dat,type = "response"))
#deviances
dev_1[i] <- CalcValidDev(pred_1,left_dat$y)
dev_2[i] <- CalcValidDev(pred_2,left_dat$y)
dev_3[i] <- CalcValidDev(pred_3,left_dat$y)
}
#saving results
tbl <- tibble("model 1"= dev_1,
"model 2"= dev_2,
"model 3"= dev_3)
write.csv(tbl,"loocv.csv")
#comparison
tibble("model 1"= mean(dev_1),
"model 2"= mean(dev_2),
"model 3"= mean(dev_3))
mod_a <- both
mod_b <- glm(y~age+university+age*university,data = bank,family = "binomial")
#g5
ht_a_5 <- ResourceSelection::hoslem.test(bank$y,predict(mod_a,type = "response"),g=5)
ht_b_5 <- ResourceSelection::hoslem.test(bank$y,predict(mod_b,type = "response"),g=5)
#g10
ht_a_10 <- ResourceSelection::hoslem.test(bank$y,predict(mod_a,type = "response"),g=10)
ht_b_10 <- ResourceSelection::hoslem.test(bank$y,predict(mod_b,type = "response"),g=10)
tibble("g"= c(5,10),
"mod_a" = c(ht_a_5$statistic,ht_a_10$statistic) ,
"mod_b" = c(ht_b_5$statistic,ht_b_10$statistic) )
ht_a_5
ht_b_5
ht_a_5
ht_b_5
ht_a_10
ht_b_10
#g5
ht_a_5 <- ResourceSelection::hoslem.test(bank$y,predict(mod_a,type = "response"),g=5)
ht_b_5 <- ResourceSelection::hoslem.test(bank$y,predict(mod_b,type = "response"),g=5)
#g10
ht_a_10 <- ResourceSelection::hoslem.test(bank$y,predict(mod_a,type = "response"),g=10)
ht_b_10 <- ResourceSelection::hoslem.test(bank$y,predict(mod_b,type = "response"),g=10)
tibble("g"= c(5,10),
"mod_a" = c(ht_a_5$statistic,ht_a_10$statistic) ,
"mod_b" = c(ht_b_5$statistic,ht_b_10$statistic) )
tbl%>% summarise_all(mean)
tbl <- write_csv("loocv.csv")
setwd("C:/Users/Nir/Desktop/מודלים ב/Stat-models-B/EX10")
tbl <- write_csv("loocv.csv")
tbl <- read_csv("loocv.csv")
tbl%>% summarise_all(mean)
tbl <- read_csv("loocv.csv") %>% select(-X1)
tbl
tbl <- read_csv("loocv.csv") %>% dplyr::select(-X1)
tbl%>% summarise_all(mean)
